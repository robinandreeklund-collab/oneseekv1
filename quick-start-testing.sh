#!/bin/bash

# SurfSense Quick Start Script for Testing with Local LLMs
# This script sets up SurfSense in testing mode (no database/auth required)

set -e  # Exit on error

echo "ðŸš€ SurfSense Quick Start - Testing Mode"
echo "========================================"
echo ""

# Check if we're in the right directory
if [ ! -d "surfsense_backend" ]; then
    echo "âŒ Error: Please run this script from the root of the SurfSense repository"
    exit 1
fi

# Check if .env already exists
if [ -f "surfsense_backend/.env" ]; then
    echo "âš ï¸  Warning: .env file already exists at surfsense_backend/.env"
    echo "Do you want to:"
    echo "  1) Backup and overwrite (creates .env.backup)"
    echo "  2) Skip .env creation (use existing)"
    echo "  3) Cancel"
    read -p "Enter choice (1/2/3): " choice
    
    case $choice in
        1)
            echo "ðŸ“¦ Creating backup..."
            cp surfsense_backend/.env surfsense_backend/.env.backup
            echo "âœ… Backup created at surfsense_backend/.env.backup"
            # Continue to create new .env
            ;;
        2)
            echo "â„¹ï¸  Using existing .env file"
            echo ""
            echo "âš ï¸  Make sure it contains:"
            echo "  DATABASE_REQUIRED=FALSE"
            echo "  AUTH_REQUIRED=FALSE"
            echo ""
            # Skip to LLM config
            skip_env_creation=true
            ;;
        3)
            echo "âŒ Cancelled"
            exit 0
            ;;
        *)
            echo "âŒ Invalid choice, cancelled"
            exit 1
            ;;
    esac
fi

# Create minimal .env file if not skipped
if [ "$skip_env_creation" != "true" ]; then
    echo "ðŸ“ Creating minimal .env configuration..."
    cat > surfsense_backend/.env << 'EOF'
# Testing mode - no database or authentication required
DATABASE_REQUIRED=FALSE
AUTH_REQUIRED=FALSE

# Minimal required settings
SECRET_KEY=test-secret-key-change-in-production
NEXT_FRONTEND_URL=http://localhost:3000

# Local embedding model (no API key needed)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Local file parser (no API key needed)
ETL_SERVICE=DOCLING

# Optional: Enable if you have Redis running
# CELERY_BROKER_URL=redis://localhost:6379/0
# CELERY_RESULT_BACKEND=redis://localhost:6379/0
EOF

    echo "âœ… Configuration file created at surfsense_backend/.env"
fi
echo ""

# Copy example LLM config if it doesn't exist
if [ ! -f "surfsense_backend/app/config/global_llm_config.yaml" ]; then
    echo "ðŸ“ Creating example LLM configuration..."
    mkdir -p surfsense_backend/app/config
    
    cat > surfsense_backend/app/config/global_llm_config.yaml << 'EOF'
global_llm_configs:
  # Ollama configuration (recommended for local testing)
  - id: -1
    name: "Local Ollama (Llama2)"
    description: "Local LLM via Ollama"
    provider: "OLLAMA"
    model_name: "llama2"
    api_base: "http://localhost:11434"
    api_key: "EMPTY"
    system_instructions: "You are a helpful AI assistant."
    citations_enabled: false

router_settings:
  routing_strategy: "usage-based-routing"
  num_retries: 3
  allowed_fails: 3
  cooldown_time: 60
EOF
    
    echo "âœ… LLM configuration created at surfsense_backend/app/config/global_llm_config.yaml"
else
    echo "â„¹ï¸  Using existing LLM configuration"
fi

echo ""
echo "ðŸŽ¯ Next Steps:"
echo "=============="
echo ""
echo "1. Start your local LLM (choose one):"
echo ""
echo "   Option A - Ollama (Recommended):"
echo "   $ ollama serve"
echo "   $ ollama pull llama2"
echo ""
echo "   Option B - vLLM:"
echo "   $ pip install vllm"
echo "   $ python -m vllm.entrypoints.openai.api_server \\"
echo "       --model meta-llama/Llama-2-7b-chat-hf \\"
echo "       --port 8001"
echo ""
echo "2. Start SurfSense backend:"
echo "   $ cd surfsense_backend"
echo "   $ python main.py"
echo ""
echo "3. (Optional) Start frontend:"
echo "   $ cd surfsense_web"
echo "   $ npm install"
echo "   $ npm run dev"
echo ""
echo "4. Access SurfSense:"
echo "   - Backend API: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Frontend: http://localhost:3000 (if started)"
echo ""
echo "ðŸ“– For more details, see TESTING_WITHOUT_DATABASE.md"
echo ""
