DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/surfsense

#Celery Config
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
# Optional: isolate queues when sharing Redis with other apps
CELERY_TASK_DEFAULT_QUEUE=surfsense

# Redis for app-level features (heartbeats, podcast markers)
# Defaults to CELERY_BROKER_URL when not set
REDIS_APP_URL=redis://localhost:6379/0

#Electric(for migrations only)
ELECTRIC_DB_USER=electric
ELECTRIC_DB_PASSWORD=electric_password

# Periodic task interval
# # Run every minute (default)
# SCHEDULE_CHECKER_INTERVAL=1m

# # Run every 5 minutes
# SCHEDULE_CHECKER_INTERVAL=5m

# # Run every 10 minutes
# SCHEDULE_CHECKER_INTERVAL=10m

# # Run every hour
# SCHEDULE_CHECKER_INTERVAL=1h

# # Run every 2 hours
# SCHEDULE_CHECKER_INTERVAL=2h
SCHEDULE_CHECKER_INTERVAL=5m

SECRET_KEY=SECRET
NEXT_FRONTEND_URL=http://localhost:3000

# Backend URL for OAuth callbacks (optional, set when behind reverse proxy with HTTPS)
# BACKEND_URL=https://api.yourdomain.com

# Auth
AUTH_TYPE=GOOGLE or LOCAL
REGISTRATION_ENABLED=TRUE or FALSE

# Anonymous access / public chat
ANON_ACCESS_ENABLED=TRUE
ANON_SESSION_TTL_SECONDS=86400
ANON_CHAT_RATE_LIMIT_MAX_REQUESTS=20
ANON_CHAT_RATE_LIMIT_WINDOW_SECONDS=60
ANON_CHAT_MAX_HISTORY_MESSAGES=10
ANON_CHAT_DEFAULT_LLM_ID=-1
ANON_CHAT_TEMPERATURE=0.2
ANON_CHAT_RECURSION_LIMIT=40
ANON_CHAT_ENABLED_TOOLS=link_preview,display_image,scrape_webpage,search_web,smhi_weather,smhi_vaderprognoser_metfcst,smhi_vaderprognoser_snow1g,smhi_vaderanalyser_mesan2g,smhi_vaderobservationer_metobs,smhi_hydrologi_hydroobs,smhi_hydrologi_pthbv,smhi_oceanografi_ocobs,smhi_brandrisk_fwif,smhi_brandrisk_fwia,trafiklab_route,libris_search,jobad_links_search

# Optional: platform-wide default runtime flags for all chat runs (new + regenerate).
# Request-level runtime_hitl still overrides these values when provided.
# ONESEEK_RUNTIME_HITL_DEFAULT_JSON={"enabled":true,"hybrid_mode":true,"speculative_enabled":true,"subagent_enabled":true,"subagent_isolation_enabled":true,"subagent_max_concurrency":3,"subagent_context_max_chars":1400,"subagent_result_max_chars":1000,"subagent_sandbox_scope":"subagent","artifact_offload_enabled":true,"artifact_offload_storage_mode":"auto","artifact_offload_threshold_chars":4000,"context_compaction_enabled":true,"context_compaction_trigger_ratio":0.65,"cross_session_memory_enabled":true,"cross_session_memory_max_items":6,"sandbox_enabled":true,"sandbox_mode":"provisioner","sandbox_provisioner_url":"http://127.0.0.1:8002","sandbox_state_store":"file","sandbox_idle_timeout_seconds":900}

# Public tool API keys (global)
PUBLIC_TAVILY_API_KEY=your_public_tavily_key_here
PUBLIC_WEB_SEARCH_MAX_RESULTS=5
TRAFIKLAB_API_KEY=your_trafiklab_api_key_here
GEOCODING_USER_AGENT=SurfSense/1.0 (+https://surfsense.ai)
JOBAD_LINKS_BASE_URL=https://links.api.jobtechdev.se
JOBAD_LINKS_API_KEY=

# Geoapify Static Maps API
GEOAPIFY_API_KEY=

# For Google Auth Only
GOOGLE_OAUTH_CLIENT_ID=924507538m
GOOGLE_OAUTH_CLIENT_SECRET=GOCSV

# Google Connector Specific Configurations
GOOGLE_CALENDAR_REDIRECT_URI=http://localhost:8000/api/v1/auth/google/calendar/connector/callback
GOOGLE_GMAIL_REDIRECT_URI=http://localhost:8000/api/v1/auth/google/gmail/connector/callback
GOOGLE_DRIVE_REDIRECT_URI=http://localhost:8000/api/v1/auth/google/drive/connector/callback

# Aitable OAuth Configuration
AIRTABLE_CLIENT_ID=your_airtable_client_id_here
AIRTABLE_CLIENT_SECRET=your_airtable_client_secret_here
AIRTABLE_REDIRECT_URI=http://localhost:8000/api/v1/auth/airtable/connector/callback

# ClickUp OAuth Configuration
CLICKUP_CLIENT_ID=your_clickup_client_id_here
CLICKUP_CLIENT_SECRET=your_clickup_client_secret_here
CLICKUP_REDIRECT_URI=http://localhost:8000/api/v1/auth/clickup/connector/callback

# Discord OAuth Configuration
DISCORD_CLIENT_ID=your_discord_client_id_here
DISCORD_CLIENT_SECRET=your_discord_client_secret_here
DISCORD_REDIRECT_URI=http://localhost:8000/api/v1/auth/discord/connector/callback
DISCORD_BOT_TOKEN=your_bot_token_from_developer_portal

# Atlassian OAuth Configuration
ATLASSIAN_CLIENT_ID=your_atlassian_client_id_here
ATLASSIAN_CLIENT_SECRET=your_atlassian_client_secret_here
JIRA_REDIRECT_URI=http://localhost:8000/api/v1/auth/jira/connector/callback
CONFLUENCE_REDIRECT_URI=http://localhost:8000/api/v1/auth/confluence/connector/callback

# Linear OAuth Configuration
LINEAR_CLIENT_ID=your_linear_client_id_here
LINEAR_CLIENT_SECRET=your_linear_client_secret_here
LINEAR_REDIRECT_URI=http://localhost:8000/api/v1/auth/linear/connector/callback

# Notion OAuth Configuration
NOTION_CLIENT_ID=your_notion_client_id_here
NOTION_CLIENT_SECRET=your_notion_client_secret_here
NOTION_REDIRECT_URI=http://localhost:8000/api/v1/auth/notion/connector/callback

# Slack OAuth Configuration
SLACK_CLIENT_ID=your_slack_client_id_here
SLACK_CLIENT_SECRET=your_slack_client_secret_here
SLACK_REDIRECT_URI=http://localhost:8000/api/v1/auth/slack/connector/callback

# Teams OAuth Configuration
TEAMS_CLIENT_ID=your_teams_client_id_here
TEAMS_CLIENT_SECRET=your_teams_client_secret_here
TEAMS_REDIRECT_URI=http://localhost:8000/api/v1/auth/teams/connector/callback

#Composio Coonnector
COMPOSIO_API_KEY=your_api_key_here
COMPOSIO_ENABLED=TRUE
COMPOSIO_REDIRECT_URI=http://localhost:8000/api/v1/auth/composio/connector/callback

# Embedding Model
# Examples:
#     # Get sentence transformers embeddings
#     embeddings = AutoEmbeddings.get_embeddings("sentence-transformers/all-MiniLM-L6-v2")

#     # Get OpenAI embeddings
#     embeddings = AutoEmbeddings.get_embeddings("openai://text-embedding-ada-002", api_key="...")

#     # Get Anthropic embeddings
#     embeddings = AutoEmbeddings.get_embeddings("anthropic://claude-v1", api_key="...")

#     # Get Cohere embeddings
#     embeddings = AutoEmbeddings.get_embeddings("cohere://embed-english-light-v3.0", api_key="...")
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Rerankers Config
RERANKERS_ENABLED=TRUE or FALSE(Default: FALSE)
RERANKERS_MODEL_NAME=ms-marco-MiniLM-L-12-v2
RERANKERS_MODEL_TYPE=flashrank

# Bolagsverket Open Data API
# BOLAGSVERKET_BASE_URL="https://gw.api.bolagsverket.se/vardefulla-datamangder/v1"
# BOLAGSVERKET_SUBSCRIPTION_KEY=""
# BOLAGSVERKET_USE_OAUTH=FALSE
# BOLAGSVERKET_API_KEY=""
# Or OAuth client credentials:
# BOLAGSVERKET_CLIENT_ID=""
# BOLAGSVERKET_CLIENT_SECRET=""
# BOLAGSVERKET_TOKEN_URL=""
# BOLAGSVERKET_SCOPE=""

# Trafikverket Open API
# TRAFIKVERKET_API_KEY=""
# TRAFIKVERKET_SCHEMA_VERSION="1.0"
# TRAFIKVERKET_SCHEMA_VERSION_FALLBACKS="1.1,1.2"


# TTS_SERVICE=local/kokoro for local Kokoro TTS or
# LiteLLM TTS Provider: https://docs.litellm.ai/docs/text_to_speech#supported-providers
TTS_SERVICE=local/kokoro
# Respective TTS Service API
# TTS_SERVICE_API_KEY=
# OPTIONAL: TTS Provider API Base
# TTS_SERVICE_API_BASE=

# STT Service Configuration
# For local Faster-Whisper: local/MODEL_SIZE (tiny, base, small, medium, large-v3)
STT_SERVICE=local/base
# For LiteLLM STT Provider: https://docs.litellm.ai/docs/audio_transcription#supported-providers
# STT_SERVICE=openai/whisper-1
# STT_SERVICE_API_KEY=""
# STT_SERVICE_API_BASE=


# (Optional) Maximum pages limit per user for ETL services (default: `999999999` for unlimited in OSS version)  
PAGES_LIMIT=500


FIRECRAWL_API_KEY=fcr-01J0000000000000000000000

# File Parser Service
ETL_SERVICE=UNSTRUCTURED or LLAMACLOUD or DOCLING
UNSTRUCTURED_API_KEY=Tpu3P0U8iy
LLAMA_CLOUD_API_KEY=llx-nnn

# OPTIONAL: Add these for LangSmith Observability
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=lsv2_pt_.....
LANGSMITH_PROJECT=surfsense

# Uvicorn Server Configuration
# Full documentation for Uvicorn options can be found at: https://www.uvicorn.org/#command-line-options
UVICORN_HOST="0.0.0.0"
UVICORN_PORT=8000
UVICORN_LOG_LEVEL=info

# OPTIONAL: Advanced Uvicorn Options (uncomment to use)
# UVICORN_PROXY_HEADERS=false
# UVICORN_FORWARDED_ALLOW_IPS="127.0.0.1"
# UVICORN_WORKERS=1
# UVICORN_ACCESS_LOG=true
# UVICORN_LOOP="auto"
# UVICORN_HTTP="auto"
# UVICORN_WS="auto"
# UVICORN_LIFESPAN="auto"
# UVICORN_LOG_CONFIG=""
# UVICORN_SERVER_HEADER=true
# UVICORN_DATE_HEADER=true
# UVICORN_LIMIT_CONCURRENCY=
# UVICORN_LIMIT_MAX_REQUESTS=
# UVICORN_TIMEOUT_KEEP_ALIVE=5
# UVICORN_TIMEOUT_NOTIFY=30
# UVICORN_SSL_KEYFILE=""
# UVICORN_SSL_CERTFILE=""
# UVICORN_SSL_KEYFILE_PASSWORD=""
# UVICORN_SSL_VERSION=""
# UVICORN_SSL_CERT_REQS=""
# UVICORN_SSL_CA_CERTS=""
# UVICORN_SSL_CIPHERS=""
# UVICORN_HEADERS=""
# UVICORN_USE_COLORS=true
# UVICORN_UDS=""
# UVICORN_FD=""
# UVICORN_ROOT_PATH=""

# ============================================================================
# LOCAL LLM / vLLM CONFIGURATION
# ============================================================================
# The platform already supports local LLMs via the OLLAMA provider in LiteLLM
# To use vLLM with your local models, you can configure it in two ways:
#
# Option 1: Use OLLAMA provider (recommended for vLLM OpenAI-compatible endpoints)
# Configure in the web UI under Search Space Settings > LLM Configurations:
#   - Provider: OLLAMA
#   - Model Name: your-model-name (e.g., "llama-2-7b")
#   - API Base: http://localhost:8000/v1 (your vLLM server endpoint)
#   - API Key: (leave empty or use "EMPTY" if your vLLM doesn't require auth)
#
# Option 2: Use CUSTOM provider for custom OpenAI-compatible endpoints
# Configure in the web UI under Search Space Settings > LLM Configurations:
#   - Provider: CUSTOM
#   - Custom Provider: "openai"
#   - Model Name: your-model-name
#   - API Base: http://localhost:8000/v1
#   - API Key: (leave empty or use your vLLM auth key)
#
# Example vLLM server setup:
# ```bash
# # Install vLLM
# pip install vllm
# 
# # Start vLLM server with OpenAI-compatible API
# python -m vllm.entrypoints.openai.api_server \
#   --model meta-llama/Llama-2-7b-chat-hf \
#   --port 8000 \
#   --host 0.0.0.0
# ```
# ============================================================================
# OLLAMA/vLLM Local LLM Configuration
# ============================================================================
#
